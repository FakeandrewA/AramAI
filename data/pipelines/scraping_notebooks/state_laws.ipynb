{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ef042db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from typing import List, Tuple, Dict\n",
    "import uuid\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "867f2e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://indiankanoon.org\"\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/115.0 Safari/537.36\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a32d9f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://indiankanoon.org/search/?formInput=doctypes:andhra-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:arunachal-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:assam-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:bihar-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:chandigarh-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:chattisgarh-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:delhi-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:goa-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:gujarat-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:haryana-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:himachal-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:jk-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:jharkhand-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:karnataka-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:kerala-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:madhyabharat-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:mp-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:mh-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:manipur-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:meghalaya-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:mizoram-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:nagaland-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:odisha-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:puducherry-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:punjab-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:rajasthan-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:sikkim-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:tn-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:telengana-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:tripura-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:uttarakhand-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:up-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:wb-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:lakshadweep-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:andaman-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:bengaluru-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:ladakh-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:daman-act%20year:',\n",
       " 'https://indiankanoon.org/search/?formInput=doctypes:dadra-act%20year:']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://indiankanoon.org/browselaws/\"\n",
    "base_url=\"https://indiankanoon.org/\"\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "statelinks = [base_url+x[\"href\"] for x in soup.table.find_all(\"a\")[4:-12]]\n",
    "statenames = [statelinks[i].split(\"/\")[-2] for i in range(len(statelinks))]\n",
    "statelinks_with_search = [f\"https://indiankanoon.org/search/?formInput=doctypes:{x}%20year:\" for x in statenames]\n",
    "statelinks_with_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7ab4e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_soup(url: str) -> BeautifulSoup:\n",
    "    \"\"\"Fetch and parse HTML from a URL.\"\"\"\n",
    "    response = requests.get(url, headers=HEADERS, timeout=10)\n",
    "    response.raise_for_status()\n",
    "    return BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "\n",
    "def get_years_of_union_act(url: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"Extract years and document counts from the union act index page.\"\"\"\n",
    "    soup = fetch_soup(url)\n",
    "    mainbody = soup.find(\"div\", class_=\"info_indian_kanoon\")\n",
    "    a_tags = mainbody.table.find_all(\"a\")\n",
    "    links = [a['href'] for a in a_tags]\n",
    "\n",
    "    count_of_docs = soup.find_all(\"div\", class_=\"browselist\")\n",
    "    years = [\n",
    "        (links[i][-5:-1], int(count_of_docs[i].a.next_sibling.strip().strip(\"()\")))\n",
    "        for i in range(len(links))\n",
    "    ]\n",
    "    return years\n",
    "\n",
    "\n",
    "def years_to_links(years: List[Tuple[str, int]], base_url: str) -> List[str]:\n",
    "    \"\"\"Convert years to full links.\"\"\"\n",
    "    return [base_url + year for year, _ in years]\n",
    "\n",
    "\n",
    "def extract_links_from_page(url: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"Extract metadata of documents from a paginated results page.\"\"\"\n",
    "    links = []\n",
    "    while url:\n",
    "        soup = fetch_soup(url)\n",
    "        results = soup.find(\"div\", class_=\"results_middle\").find_all(\"div\", class_=\"result\")\n",
    "\n",
    "        for result in results:\n",
    "            cite_tags = result.find_all(\"a\", class_=\"cite_tag\")\n",
    "            cited_to = int(cite_tags[0].text.split()[-1]) if cite_tags else 0\n",
    "            cited_by = int(cite_tags[1].text.split()[-1]) if len(cite_tags) > 1 else 0\n",
    "\n",
    "            links.append({\n",
    "                \"doc_id\": str(uuid.uuid4()),\n",
    "                \"link\": BASE_URL + result.a[\"href\"],\n",
    "                \"title\": result.a.text,\n",
    "                \"docsource\": result.span.text,\n",
    "                \"cited_to\": cited_to,\n",
    "                \"cited_by\": cited_by,\n",
    "            })\n",
    "\n",
    "        # Check if there's a \"Next\" page\n",
    "        next_page = soup.find(\"div\", class_=\"bottom\").find(\"a\", string=\"Next\")\n",
    "        url = BASE_URL + next_page['href'] if next_page else None\n",
    "\n",
    "    return links\n",
    "\n",
    "\n",
    "def organize_links(links: List[str]) -> Dict[str, List[Dict[str, str]]]:\n",
    "    \"\"\"Organize document links by year.\"\"\"\n",
    "    organized_links = {}\n",
    "    for link in links:\n",
    "        year = link[-4:]\n",
    "        if year not in organized_links:\n",
    "            organized_links[year] = extract_links_from_page(link)\n",
    "    return organized_links\n",
    "\n",
    "\n",
    "def attach_document_count_to_metadata(\n",
    "    metadata: Dict[str, List[Dict[str, str]]],\n",
    "    years: List[Tuple[str, int]]\n",
    ") -> Dict[str, List[Dict[str, str]]]:\n",
    "    \"\"\"Attach document counts to metadata for verification.\"\"\"\n",
    "    metadata[\"document_count\"] = {year: count for year, count in years}\n",
    "    return metadata\n",
    "\n",
    "\n",
    "def verify_document_count_in_metadata(metadata: Dict[str, List[Dict[str, str]]]) -> None:\n",
    "    \"\"\"Verify if document counts match expected counts.\"\"\"\n",
    "    for year in metadata:\n",
    "        if year == \"document_count\":\n",
    "            continue\n",
    "        expected = metadata[\"document_count\"].get(year, 0)\n",
    "        found = len(metadata[year])\n",
    "        if found == expected:\n",
    "            print(f\"✅ Document count matches for {year}\")\n",
    "        else:\n",
    "            print(f\"❌ Mismatch for {year}: expected {expected}, found {found}\")\n",
    "\n",
    "\n",
    "def attach_data_to_metadata(\n",
    "    metadata: Dict[str, List[Dict[str, str]]],\n",
    "    years: List[str]\n",
    ") -> Dict[str, List[Dict[str, str]]]:\n",
    "    \"\"\"Fetch full document text for each case and attach it to metadata.\"\"\"\n",
    "    for year in years:\n",
    "        for doc in metadata.get(year, []):\n",
    "            link = doc[\"link\"]\n",
    "            print(f\"Fetching data for {doc['title']} , year: {year}, link: {link}\")\n",
    "\n",
    "            data, success = \"\", False\n",
    "            for attempt in range(3):  # try max 3 times\n",
    "                try:\n",
    "                    response = requests.get(link, headers=HEADERS, timeout=10)\n",
    "                    response.raise_for_status()\n",
    "                    sleep(2)  # polite delay\n",
    "\n",
    "                    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "                    container = soup.find(\"div\", class_=\"akn-akomaNtoso\")\n",
    "                    if container:\n",
    "                        data = container.get_text(\" \", strip=True)\n",
    "                        success = True\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    print(f\"Attempt {attempt+1} failed for {doc['title']} ({year}) -> {e}\")\n",
    "                    sleep(3)\n",
    "\n",
    "            if not success:\n",
    "                print(f\"❌ Could not fetch data for {doc['title']} , year: {year}\")\n",
    "\n",
    "            doc[\"data\"] = data\n",
    "\n",
    "    return metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe39e690",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(statelinks_with_search)):\n",
    "    print(\"Processing state:\", statenames[i])\n",
    "    base_url = statelinks_with_search[i]\n",
    "    url = statelinks[i]\n",
    "    years = get_years_of_union_act(url)\n",
    "    links = years_to_links(years, base_url)\n",
    "    metadata = organize_links(links)\n",
    "    attach_document_count_to_metadata(metadata, years)\n",
    "    verify_document_count_in_metadata(metadata)\n",
    "    attach_data_to_metadata(metadata, [year for year, _ in years])\n",
    "    with open(f\"../scraped_data/{statenames[i]}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metadata, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"Completed processing for state: {statenames[i]}..................................\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
